mutate(word = gsub("^ +| +$|( ) +", "\\1", word)) %>%
mutate(word = str_replace(word,"alaska|delta|united|southwest|americanair","")) %>%
filter(word != "") %>%
count(airline, word, sort = TRUE) %>%
group_by(airline) %>%
summarize(total = sum(n))
tidy_2021 <- left_join(tidy_2021, total_2021, by = airline)
tidy_2021 <- left_join(tidy_2021, total_2021, by = 'airline')
View(tidy_2021)
airline_tf_idf <- tidy_2021 %>%
bind_tf_idf(word, airline, n)
airline_tf_idf %>%
group_by(airline) %>%
slice_max(tf_idf, n = 15) %>%
ungroup() %>%
ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill = book)) +
geom_col(show.legend = FALSE) +
facet_wrap(~airline, ncol = 2, scales = "free") +
labs(x = "tf-idf", y = NULL)
airline_tf_idf %>%
group_by(airline) %>%
slice_max(tf_idf, n = 15) %>%
ungroup() %>%
ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill = airline)) +
geom_col(show.legend = FALSE) +
facet_wrap(~airline, ncol = 2, scales = "free") +
labs(x = "tf-idf", y = NULL)
airline_tf_idf %>%
group_by(airline) %>%
slice_max(n, n = 15) %>%
ungroup() %>%
ggplot(aes(tf_idf, fct_reorder(word, n), fill = airline)) +
geom_col(show.legend = FALSE) +
facet_wrap(~airline, ncol = 2, scales = "free") +
labs(x = "tf-idf", y = NULL)
airline_tf_idf %>%
group_by(airline) %>%
slice_max(n, n = 15) %>%
ungroup() %>%
ggplot(aes(n, fct_reorder(word, n), fill = airline)) +
geom_col(show.legend = FALSE) +
facet_wrap(~airline, ncol = 2, scales = "free") +
labs(x = "tf-idf", y = NULL)
airline_tf_idf %>%
group_by(airline) %>%
slice_max(n, n = 5) %>%
ungroup() %>%
ggplot(aes(n, fct_reorder(word, n), fill = airline)) +
geom_col(show.legend = FALSE) +
facet_wrap(~airline, ncol = 2, scales = "free") +
labs(x = "tf-idf", y = NULL)
airline_tf_idf %>%
group_by(airline) %>%
slice_max(n, n = 5) %>%
ungroup() %>%
ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill = airline)) +
geom_col(show.legend = FALSE) +
facet_wrap(~airline, ncol = 2, scales = "free") +
labs(x = "tf-idf", y = NULL)
airline_tf_idf %>%
group_by(airline) %>%
slice_head(n, tf_idf = 5) %>%
ungroup() %>%
ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill = airline)) +
geom_col(show.legend = FALSE) +
facet_wrap(~airline, ncol = 2, scales = "free") +
labs(x = "tf-idf", y = NULL)
airline_tf_idf %>%
group_by(airline) %>%
slice_max(n, tf_idf = 5) %>%
ungroup() %>%
ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill = airline)) +
geom_col(show.legend = FALSE) +
facet_wrap(~airline, ncol = 2, scales = "free") +
labs(x = "tf-idf", y = NULL)
airline_tf_idf %>%
group_by(airline) %>%
slice_head(tf_idf, n = 5) %>%
ungroup() %>%
ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill = airline)) +
geom_col(show.legend = FALSE) +
facet_wrap(~airline, ncol = 2, scales = "free") +
labs(x = "tf-idf", y = NULL)
airline_tf_idf %>%
group_by(airline) %>%
slice_max(tf_idf, n = 5) %>%
ungroup() %>%
ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill = airline)) +
geom_col(show.legend = FALSE) +
facet_wrap(~airline, ncol = 2, scales = "free") +
labs(x = "tf-idf", y = NULL)
airline_tf_idf %>%
group_by(airline) %>%
slice_head(n, n = 5) %>%
ungroup() %>%
ggplot(aes(n, fct_reorder(word, n), fill = airline)) +
geom_col(show.legend = FALSE) +
facet_wrap(~airline, ncol = 2, scales = "free") +
labs(x = "tf-idf", y = NULL)
airline_tf_idf %>%
group_by(airline) %>%
slice_head(n = 5) %>%
ungroup() %>%
ggplot(aes(n, fct_reorder(word, n), fill = airline)) +
geom_col(show.legend = FALSE) +
facet_wrap(~airline, ncol = 2, scales = "free") +
labs(x = "tf-idf", y = NULL)
airline_tf_idf %>%
group_by(airline) %>%
slice_max(tf_idf = 5) %>%
ungroup() %>%
ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill = airline)) +
geom_col(show.legend = FALSE) +
facet_wrap(~airline, ncol = 2, scales = "free") +
labs(x = "tf-idf", y = NULL)
airline_tf_idf %>%
group_by(airline) %>%
slice_max(tf_idf, n = 5) %>%
ungroup() %>%
ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill = airline)) +
geom_col(show.legend = FALSE) +
facet_wrap(~airline, ncol = 2, scales = "free") +
labs(x = "tf-idf", y = NULL)
austen_books()
library(janeaustenr)
austen_books()
knitr::opts_chunk$set(echo = TRUE)
tidy_books <- austen_books() %>%
group_by(book) %>%
mutate(
linenumber = row_number(),
chapter = cumsum(str_detect(text,
regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup()
library(tidyverse)
library(RColorBrewer)
library(tidytext)
library(tm)
tidy_books <- austen_books() %>%
group_by(book) %>%
mutate(
linenumber = row_number(),
chapter = cumsum(str_detect(text,
regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup()
View(tidy_books)
austen_section_words <- austen_books() %>%
filter(book == "Pride & Prejudice") %>%
mutate(section = row_number() %/% 10) %>%
filter(section > 0)
View(austen_section_words)
View(tidy_books)
setwd("~/dataviz2021/Group_Project/Andrew_Text")
a2021 <- read_csv("airline2021.csv")
a2015 <- read_csv("airlinetweets2015.csv")
df <- a2021 %>%
select(status_id,created_at,text,
mentions_screen_name,location,retweet_count, hashtags)
check <- df %>%
mutate(mentions_screen_name = str_extract_all(mentions_screen_name,
'(?<=")[A-Za-z]+')) %>%
unnest(., mentions_screen_name) %>%
mutate(hashtags = str_extract_all(hashtags, '(?<=")[A-Za-z]+')) %>%
unnest(., hashtags) %>%
group_by(status_id) %>%
mutate(mentions_screen_name =
ifelse(is.na(mentions_screen_name),hashtags,mentions_screen_name)) %>%
mutate(hashtags =
ifelse(is.na(hashtags), mentions_screen_name,hashtags)) %>%
mutate(mentions_screen_name = tolower(mentions_screen_name))
# Tweets that only reference on airline
# Need to find a way to show that mentions include more than one airline
# Might delete code for stacked bar chart
clean <- check %>%
filter(str_detect(mentions_screen_name,
'alaska|delta|united|southwest|americanair')) %>%
group_by(status_id) %>%
mutate(n = n(),
is_dupe = ifelse(n > 1,1,0)) %>%
filter(is_dupe == 0) %>%
filter(row_number()==1) %>%
select(status_id,created_at,text,
mentions_screen_name,location,retweet_count) %>%
rename(airline = mentions_screen_name) %>%
mutate(airline = case_when(airline == "alaskaair" ~ "AlaskaAir",
airline %in% c("americanair","americanairlines",
"americanairlnes") ~
"AmericanAir",
airline %in% c("delta", "deltaairline") ~ "DeltaAir",
airline == "southwestair" ~ "SouthwestAir",
airline == "united" ~ "United")) %>%
ungroup()
clean %>%
mutate(section = row_number() %/% 5) %>%
filter(section > 0)  %>%
unnest_tokens(output = word, input = text) %>%
anti_join(bind_rows(stop_words, data.frame(word = c("rt", "https"),
lexicon = "TWITTER")),
by = "word") %>%
mutate(word =  gsub("[[:punct:][:blank:]]+", "", word)) %>%
mutate(word = gsub("[0-9]+", "", word)) %>%
mutate(word =  gsub("*\\b[[:alpha:]]{1,2}\\b *", "", word)) %>%
mutate(word =  gsub("\\b[A-Z]+\\b", "", word)) %>%
mutate(word = gsub("^ +| +$|( ) +", "\\1", word)) %>%
filter(word != "")
clean %>%
mutate(section = row_number() %/% 5) %>%
filter(section > 0)  %>%
unnest_tokens(output = word, input = text) %>%
anti_join(bind_rows(stop_words, data.frame(word = c("rt", "https"),
lexicon = "TWITTER")),
by = "word") %>%
mutate(word =  gsub("[[:punct:][:blank:]]+", "", word)) %>%
mutate(word = gsub("[0-9]+", "", word)) %>%
mutate(word =  gsub("*\\b[[:alpha:]]{1,2}\\b *", "", word)) %>%
mutate(word =  gsub("\\b[A-Z]+\\b", "", word)) %>%
mutate(word = gsub("^ +| +$|( ) +", "\\1", word)) %>%
filter(word != "") %>%
pairwise_count(word, section, sort = TRUE)
install.packages('widyr')
library(tidyverse)
library(RColorBrewer)
library(tidytext)
library(tm)
library(widyr)
clean %>%
mutate(section = row_number() %/% 5) %>%
filter(section > 0)  %>%
unnest_tokens(output = word, input = text) %>%
anti_join(bind_rows(stop_words, data.frame(word = c("rt", "https"),
lexicon = "TWITTER")),
by = "word") %>%
mutate(word =  gsub("[[:punct:][:blank:]]+", "", word)) %>%
mutate(word = gsub("[0-9]+", "", word)) %>%
mutate(word =  gsub("*\\b[[:alpha:]]{1,2}\\b *", "", word)) %>%
mutate(word =  gsub("\\b[A-Z]+\\b", "", word)) %>%
mutate(word = gsub("^ +| +$|( ) +", "\\1", word)) %>%
filter(word != "") %>%
pairwise_count(word, section, sort = TRUE)
library(tidyverse)
library(tidytext)
library(widyr)
library(ggraph)
library(igraph)
library(tidygraph)
## Load Data
clean <- readRDS('Cleaned_Text2021.RData')
## Create Tidy
tidy_2021 <- clean %>%
mutate(text = tolower(text)) %>%
unnest_tokens(output = word, input = text) %>%
anti_join(bind_rows(stop_words, data.frame(word = c("rt", "https"),
lexicon = "TWITTER")),
by = "word") %>%
mutate(word =  gsub("[[:punct:][:blank:]]+", "", word)) %>%
mutate(word = gsub("[0-9]+", "", word)) %>%
mutate(word =  gsub("*\\b[[:alpha:]]{1,2}\\b *", "", word)) %>%
mutate(word =  gsub("\\b[A-Z]+\\b", "", word)) %>%
mutate(word = gsub("^ +| +$|( ) +", "\\1", word)) %>%
mutate(word = str_replace(word,"alaska|delta|united|southwest|americanair","")) %>%
filter(word != "") %>%
count(airline, word, sort = TRUE)
## Join Sentiment
valence <- inner_join(tidy_2021, get_sentiments("afinn"), by = "word")
## Graph
valence_graph <- ggplot(valence) +
geom_boxplot(aes(x = airline, y = value, color = airline), show.legend = FALSE) +
ylim(-5, 5) +
labs(x = "Airlines", y = "AFINN Values") +
ggtitle("Sentiment Value Distribution By Airlines") +
theme(plot.title = element_text(vjust=2, hjust = 0.5))
## Save
ggsave(valence_graph, file="valence_graph.png", dpi = 1000)
setwd("~/dataviz2021/Group_Project/Andrew_Text")
library(tidyverse)
library(tidytext)
library(widyr)
library(ggraph)
library(igraph)
library(tidygraph)
## Load Data
setwd("~/dataviz2021/Group_Project/Andrew_Text")
clean <- readRDS('Cleaned_Text2021.RData')
## Create Tidy
tidy_2021 <- clean %>%
mutate(text = tolower(text)) %>%
unnest_tokens(output = word, input = text) %>%
anti_join(bind_rows(stop_words, data.frame(word = c("rt", "https"),
lexicon = "TWITTER")),
by = "word") %>%
mutate(word =  gsub("[[:punct:][:blank:]]+", "", word)) %>%
mutate(word = gsub("[0-9]+", "", word)) %>%
mutate(word =  gsub("*\\b[[:alpha:]]{1,2}\\b *", "", word)) %>%
mutate(word =  gsub("\\b[A-Z]+\\b", "", word)) %>%
mutate(word = gsub("^ +| +$|( ) +", "\\1", word)) %>%
mutate(word = str_replace(word,"alaska|delta|united|southwest|americanair","")) %>%
filter(word != "") %>%
count(airline, word, sort = TRUE)
## Join Sentiment
valence <- inner_join(tidy_2021, get_sentiments("afinn"), by = "word")
## Graph
valence_graph <- ggplot(valence) +
geom_boxplot(aes(x = airline, y = value, color = airline), show.legend = FALSE) +
ylim(-5, 5) +
labs(x = "Airlines", y = "AFINN Values") +
ggtitle("Sentiment Value Distribution By Airlines") +
theme(plot.title = element_text(vjust=2, hjust = 0.5))
## Save
ggsave(valence_graph, file="valence_graph.png", dpi = 1000)
library(tidyverse)
library(tidytext)
library(widyr)
library(ggraph)
library(igraph)
library(tidygraph)
## Load Data
setwd("~/dataviz2021/Group_Project/Andrew_Text")
clean <- readRDS('Cleaned_Text2021.RData')
## Create Tidy
tidy_2021 <- clean %>%
mutate(text = tolower(text)) %>%
unnest_tokens(output = word, input = text) %>%
anti_join(bind_rows(stop_words, data.frame(word = c("rt", "https"),
lexicon = "TWITTER")),
by = "word") %>%
mutate(word =  gsub("[[:punct:][:blank:]]+", "", word)) %>%
mutate(word = gsub("[0-9]+", "", word)) %>%
mutate(word =  gsub("*\\b[[:alpha:]]{1,2}\\b *", "", word)) %>%
mutate(word =  gsub("\\b[A-Z]+\\b", "", word)) %>%
mutate(word = gsub("^ +| +$|( ) +", "\\1", word)) %>%
mutate(word = str_replace(word,"alaska|delta|united|southwest|americanair","")) %>%
filter(word != "") %>%
count(airline, word, sort = TRUE)
## Join Sentiment
valence <- inner_join(tidy_2021, get_sentiments("afinn"), by = "word")
## Graph
valence_graph <- ggplot(valence) +
geom_boxplot(aes(x = airline, y = value, color = airline), show.legend = FALSE) +
ylim(-5, 5) +
labs(x = "Airlines", y = "AFINN Values") +
ggtitle("Sentiment Value Distribution By Airlines") +
theme(plot.title = element_text(vjust=2, hjust = 0.5))
## Save
ggsave(valence_graph, file="valence_graph.png", width = 12, height = 6, dpi = 1000)
library(tidyverse)
library(tidytext)
library(widyr)
library(ggraph)
library(igraph)
library(tidygraph)
## Load Data
setwd("~/dataviz2021/Group_Project/Andrew_Text")
clean <- readRDS('Cleaned_Text2021.RData')
## Create Tidy
tidy_2021 <- clean %>%
mutate(text = tolower(text)) %>%
unnest_tokens(output = word, input = text) %>%
anti_join(bind_rows(stop_words, data.frame(word = c("rt", "https"),
lexicon = "TWITTER")),
by = "word") %>%
mutate(word =  gsub("[[:punct:][:blank:]]+", "", word)) %>%
mutate(word = gsub("[0-9]+", "", word)) %>%
mutate(word =  gsub("*\\b[[:alpha:]]{1,2}\\b *", "", word)) %>%
mutate(word =  gsub("\\b[A-Z]+\\b", "", word)) %>%
mutate(word = gsub("^ +| +$|( ) +", "\\1", word)) %>%
mutate(word = str_replace(word,"alaska|delta|united|southwest|americanair","")) %>%
filter(word != "") %>%
count(airline, word, sort = TRUE)
## Join Sentiment
valence <- inner_join(tidy_2021, get_sentiments("afinn"), by = "word")
## Graph
valence_graph <- ggplot(valence) +
geom_boxplot(aes(x = airline, y = value, color = airline), show.legend = FALSE) +
ylim(-5, 5) +
labs(x = "Airlines", y = "AFINN Values") +
ggtitle("Sentiment Value Distribution By Airlines") +
theme(plot.title = element_text(vjust=2, hjust = 0.5))
## Save
ggsave(valence_graph, file="valence_graph.png", width = 10, height = 6, dpi = 1000)
library(tidyverse)
library(tidytext)
library(widyr)
library(ggraph)
library(igraph)
library(tidygraph)
## Load Data
setwd("~/dataviz2021/Group_Project/Andrew_Text")
clean <- readRDS('Cleaned_Text2021.RData')
## Cleaning and preparing for correlation
word_cors <- clean %>%
mutate(section = row_number() %/% 10) %>%
filter(section > 0)  %>%
unnest_tokens(output = word, input = text) %>%
anti_join(bind_rows(stop_words, data.frame(word = c("rt", "https"),
lexicon = "TWITTER")),
by = "word") %>%
mutate(word =  gsub("[[:punct:][:blank:]]+", "", word)) %>%
mutate(word = gsub("[0-9]+", "", word)) %>%
mutate(word =  gsub("*\\b[[:alpha:]]{1,2}\\b *", "", word)) %>%
mutate(word =  gsub("\\b[A-Z]+\\b", "", word)) %>%
mutate(word = gsub("^ +| +$|( ) +", "\\1", word)) %>%
filter(word != "") %>%
group_by(word) %>%
filter(n() >= 20) %>%
pairwise_cor(word, section, sort = TRUE)
## Making Edge
textg <- word_cors %>%
mutate(item1 = case_when(item1 == "alaskaair" ~ "AlaskaAir",
item1 %in% c("americanair","americanairlines",
"americanairlnes") ~
"AmericanAir",
item1 %in% c("delta", "deltaairline") ~ "DeltaAir",
item1 == "southwestair" ~ "SouthwestAir",
item1 == "united" ~ "United")) %>%
mutate(airline = case_when(item1 == "AlaskaAir" ~ "AlaskaAir",
item1 == "AmericanAir" ~ "AmericanAir",
item1 == "DeltaAir" ~ "DeltaAir",
item1 == "SouthwestAir" ~ "SouthwestAir",
item1 == "United" ~ "United")) %>%
filter(airline %in% c("United", "SouthwestAir", "DeltaAir",
"AlaskaAir", "AmericanAir")) %>%
filter(correlation > 0.30) %>%
graph_from_data_frame()
## Categorizing by airline
V(textg)$airline <- as.character(clean$airline[match(V(textg)$name,
as.character(clean$airline))])
g_tbl <- as_tbl_graph(textg)
node_from <- g_tbl %>%
as_tibble() %>%
mutate(from = row_number())
new_g_tbl <- g_tbl %>%
activate(edges) %>%
left_join(node_from)
### Graph
set.seed(2021)
windows.options(width=3.75, height=3.75)
cor_graph <- ggraph(new_g_tbl, layout = "fr") +
geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
geom_node_point(aes(color = airline), size = 5) +
geom_node_text(aes(label = name), repel = TRUE) +
ggtitle("Word Correlation Network By Airlines") +
theme(panel.background = element_blank(),
strip.background = element_rect(colour=NA, fill=NA),
legend.position =  'none',
plot.title = element_text(vjust=2, hjust = 0.5))
## Save
ggsave(cor_graph, file="cor_graph.png", width = 10, height = 6, dpi = 1000)
library(tidyverse)
library(tidytext)
library(widyr)
library(ggraph)
library(igraph)
library(tidygraph)
## Load Data and Cleaning Strings
setwd("~/dataviz2021/Group_Project/Andrew_Text")
clean <- readRDS('Cleaned_Text2021.RData')
tidy_2021 <- clean %>%
mutate(text = tolower(text)) %>%
unnest_tokens(output = word, input = text) %>%
anti_join(bind_rows(stop_words, data.frame(word = c("rt", "https"),
lexicon = "TWITTER")),
by = "word") %>%
mutate(word =  gsub("[[:punct:][:blank:]]+", "", word)) %>%
mutate(word = gsub("[0-9]+", "", word)) %>%
mutate(word =  gsub("*\\b[[:alpha:]]{1,2}\\b *", "", word)) %>%
mutate(word =  gsub("\\b[A-Z]+\\b", "", word)) %>%
mutate(word = gsub("^ +| +$|( ) +", "\\1", word)) %>%
mutate(word = str_replace(word,"alaska|delta|united|southwest|americanair","")) %>%
filter(word != "") %>%
count(airline, word, sort = TRUE)
## Total Word for String
total_2021 <- clean %>%
mutate(text = tolower(text)) %>%
unnest_tokens(output = word, input = text) %>%
anti_join(bind_rows(stop_words, data.frame(word = c("rt", "https"),
lexicon = "TWITTER")),
by = "word") %>%
mutate(word =  gsub("[[:punct:][:blank:]]+", "", word)) %>%
mutate(word = gsub("[0-9]+", "", word)) %>%
mutate(word =  gsub("*\\b[[:alpha:]]{1,2}\\b *", "", word)) %>%
mutate(word =  gsub("\\b[A-Z]+\\b", "", word)) %>%
mutate(word = gsub("^ +| +$|( ) +", "\\1", word)) %>%
mutate(word = str_replace(word,"alaska|delta|united|southwest|americanair","")) %>%
filter(word != "") %>%
count(airline, word, sort = TRUE) %>%
group_by(airline) %>%
summarize(total = sum(n))
## Joining datadrame
tidy_2021 <- left_join(tidy_2021, total_2021, by = 'airline')
## Finding TF-IDF Score
airline_tf_idf <- tidy_2021 %>%
bind_tf_idf(word, airline, n)
## Graph
tfidf_graph <- airline_tf_idf %>%
group_by(airline) %>%
slice_max(tf_idf, n = 5) %>%
ungroup() %>%
ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill = airline)) +
geom_col(show.legend = FALSE) +
facet_wrap(~airline, ncol = 2, scales = "free") +
scale_x_continuous(labels = scales::number_format(accuracy = 0.001,
decimal.mark = '.')) +
labs(x = "Term Frequencyâ€“Inverse Document Frequency",
y = 'Top 5 Words From Tweets') +
ggtitle("TF-IDF Score by Airline Tweets") +
theme(plot.title = element_text(vjust=2, hjust = 0.5),
axis.title.x = element_text(vjust = -1),
axis.title.y = element_text(vjust = 1))
## Save
ggsave(tfidf_graph, file="tfidf_graph.png", width = 10, height = 6, dpi = 1000)
